{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5b839033",
      "metadata": {
        "id": "5b839033"
      },
      "source": [
        "## Prepare the runtime environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1b7da88",
      "metadata": {
        "id": "a1b7da88"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/zjunlp/EasyEdit\n",
        "%cd EasyEdit\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44f3eac3",
      "metadata": {
        "id": "44f3eac3"
      },
      "outputs": [],
      "source": [
        "!apt-get install python3.9\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 1\n",
        "!sudo update-alternatives --config python3\n",
        "!apt-get install python3-pip\n",
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4135a608",
      "metadata": {
        "id": "4135a608"
      },
      "source": [
        "## Config Method Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5912a228",
      "metadata": {
        "id": "5912a228"
      },
      "source": [
        "\n",
        "\n",
        "```python\n",
        "# For LoRA hparams:\n",
        "alg_name: \"LoRA\"\n",
        "model_name: \"./hugging_cache/llama-7b\"\n",
        "device: 0\n",
        "layers: [4, 5, 6, 7]\n",
        "clamp_norm_factor: 0.75\n",
        "layer_selection: \"all\"\n",
        "fact_token: \"subject_last\"\n",
        "v_num_grad_steps: 20\n",
        "v_lr: 5e-1\n",
        "v_loss_layer: 31\n",
        "v_weight_decay: 0.5\n",
        "kl_factor: 0.0625\n",
        "mom2_adjustment: true\n",
        "mom2_update_weight: 20000\n",
        "rewrite_module_tmp: \"model.layers.{}.mlp.down_proj\"\n",
        "layer_module_tmp: \"model.layers.{}\"\n",
        "mlp_module_tmp: \"model.layers.{}.mlp\"\n",
        "attn_module_tmp:  \"model.layers.{}.self_attn\"\n",
        "ln_f_module: \"model.norm\"\n",
        "lm_head_module: \"lm_head\"\n",
        "mom2_dataset: \"wikipedia\"\n",
        "mom2_n_samples: 100000\n",
        "mom2_dtype: \"float32\"\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b2181cd",
      "metadata": {
        "id": "3b2181cd"
      },
      "source": [
        "## Import modules & Run"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d1f9557",
      "metadata": {
        "id": "3d1f9557"
      },
      "source": [
        "### Edit llama-7b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "818879db",
      "metadata": {
        "id": "818879db"
      },
      "outputs": [],
      "source": [
        "# Step 1: Load the model editor e.g.\n",
        "from easyeditor import BaseEditor, LoRAHyperParams\n",
        "hparams = LoRAHyperParams.from_hparams(NAME_OR_PATH)\n",
        "editor = BaseEditor.from_hparams(hparams)\n",
        "\n",
        "# Step 2: Prepare the editing descriptor\n",
        "prompts = ['Who is the chancellor of UC Berkeley?']\n",
        "target_new = ['Rich Lyons']\n",
        "\n",
        "# Step3: Edit and Evaluate\n",
        "metrics, edited_model = editor.edit(\n",
        "    prompts=prompts,\n",
        "    target_new=target_new\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f12ea423",
      "metadata": {
        "id": "f12ea423"
      },
      "outputs": [],
      "source": [
        "hparams= LoRAHyperParams.from_hparams('./hparams/LoRA/llama-7b.yaml')\n",
        "\n",
        "prompts = ['Who was the designer of Lahti Town Hall?',\n",
        "                'What role does Denny Herzig play in football?',\n",
        "                'What city did Marl Young live when he died?']\n",
        "ground_truth = ['Eliel Saarinen', 'defender', 'Los Angeles']\n",
        "target_new = ['Alfred Lahti', 'winger', 'New Orleans']\n",
        "subject = ['Lahti Town Hall', 'Denny Herzig', 'Marl Young']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cf8b6de",
      "metadata": {
        "id": "5cf8b6de"
      },
      "outputs": [],
      "source": [
        "editor=BaseEditor.from_hparams(hparams)\n",
        "metrics, edited_model, _ = editor.edit(\n",
        "    prompts=prompts,\n",
        "    ground_truth=ground_truth,\n",
        "    target_new=target_new,\n",
        "    subject=subject,\n",
        "    keep_original_weight=False\n",
        ")\n",
        "print(metrics)\n",
        "print(type(edited_model))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73ee2632",
      "metadata": {
        "id": "73ee2632"
      },
      "source": [
        "#### Reliability Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ffcafed",
      "metadata": {
        "id": "0ffcafed"
      },
      "outputs": [],
      "source": [
        "from transformers import LlamaTokenizer\n",
        "from transformers import LlamaForCausalLM\n",
        "tokenizer = LlamaTokenizer.from_pretrained('./hugging_cache/llama-7b', cache_dir='./hugging_cache')\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "tokenizer.padding_side='left'\n",
        "\n",
        "correct_prompts = ['Who was the designer of Lahti Town Hall?',\n",
        "                'What role does Denny Herzig play in football?',\n",
        "                'What city did Marl Young live when he died?']\n",
        "\n",
        "model = LlamaForCausalLM.from_pretrained('./hugging_cache/llama-7b', cache_dir='./hugging_cache').to('cuda')\n",
        "batch = tokenizer(correct_prompts, return_tensors='pt', padding=True, max_length=30)\n",
        "\n",
        "pre_edit_outputs = model.generate(\n",
        "    input_ids=batch['input_ids'].to('cuda'),\n",
        "    attention_mask=batch['attention_mask'].to('cuda'),\n",
        "    max_new_tokens=8\n",
        "\n",
        ")\n",
        "\n",
        "post_edit_outputs = edited_model.generate(\n",
        "    input_ids=batch['input_ids'].to('cuda'),\n",
        "    attention_mask=batch['attention_mask'].to('cuda'),\n",
        "    max_new_tokens=8\n",
        ")\n",
        "print('Pre-Edit Outputs: ', [tokenizer.decode(x) for x in pre_edit_outputs.detach().cpu().numpy().tolist()])\n",
        "print('Post-Edit Outputs: ', [tokenizer.decode(x) for x in post_edit_outputs.detach().cpu().numpy().tolist()])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "660dcef9",
      "metadata": {
        "id": "660dcef9"
      },
      "source": [
        "#### Generalization test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a49753a6",
      "metadata": {
        "id": "a49753a6"
      },
      "outputs": [],
      "source": [
        "generation_prompts = ['Who was the architect behind the design of Lahti Town Hall?',\n",
        "'What position does Denny Herzig hold in the sport of football?',\n",
        "'In what city was Marl Young residing at the time of his death?']\n",
        "\n",
        "batch = tokenizer(generation_prompts, return_tensors='pt', padding=True, max_length=30)\n",
        "\n",
        "pre_edit_outputs = model.generate(\n",
        "    input_ids=batch['input_ids'].to('cuda'),\n",
        "    attention_mask=batch['attention_mask'].to('cuda'),\n",
        "    max_new_tokens=8\n",
        ")\n",
        "\n",
        "post_edit_outputs = edited_model.generate(\n",
        "    input_ids=batch['input_ids'].to('cuda'),\n",
        "    attention_mask=batch['attention_mask'].to('cuda'),\n",
        "    max_new_tokens=8\n",
        ")\n",
        "\n",
        "print('Pre-Edit Outputs: ', [tokenizer.decode(x) for x in pre_edit_outputs.detach().cpu().numpy().tolist()])\n",
        "print('Post-Edit Outputs: ', [tokenizer.decode(x) for x in post_edit_outputs.detach().cpu().numpy().tolist()])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faf5cb84",
      "metadata": {
        "id": "faf5cb84"
      },
      "source": [
        "#### Locality test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9029f238",
      "metadata": {
        "id": "9029f238"
      },
      "outputs": [],
      "source": [
        "locality_prompts = ['Who was the designer of Eiffel Tower?',\n",
        "                'What role does Messi play in football?',\n",
        "                'What city did Madame Curie live when he died?']\n",
        "\n",
        "batch = tokenizer(locality_prompts, return_tensors='pt', padding=True, max_length=30)\n",
        "\n",
        "pre_edit_outputs = model.generate(\n",
        "    input_ids=batch['input_ids'].to('cuda'),\n",
        "    attention_mask=batch['attention_mask'].to('cuda'),\n",
        "    max_new_tokens=8\n",
        ")\n",
        "\n",
        "post_edit_outputs = edited_model.generate(\n",
        "    input_ids=batch['input_ids'].to('cuda'),\n",
        "    attention_mask=batch['attention_mask'].to('cuda'),\n",
        "    max_new_tokens=8\n",
        ")\n",
        "\n",
        "print('Pre-Edit Outputs: ', [tokenizer.decode(x) for x in pre_edit_outputs.detach().cpu().numpy().tolist()])\n",
        "print('Post-Edit Outputs: ', [tokenizer.decode(x) for x in post_edit_outputs.detach().cpu().numpy().tolist()])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### KnowEdit"
      ],
      "metadata": {
        "id": "G5WKG_mz24JE"
      },
      "id": "G5WKG_mz24JE"
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from easyeditor import FTHook, MEMITHook, ROMEHook\n",
        "from easyeditor import EditTrainer\n",
        "from easyeditor import ZsreDataset\n",
        "import torch\n",
        "\n",
        "dataset = KnowEditDataset(\"zjunlp/KnowEdit\")\n",
        "zsre_dataset = dataset[\"zsre\"]\n",
        "edit_examples = []\n",
        "for example in zsre_dataset[\"train\"]:\n",
        "    edit_examples.append({\n",
        "        \"prompt\": f\"{example['subject']} {example['prompt']}\",\n",
        "        \"target_new\": example[\"target_new\"],\n",
        "        \"ground_truth\": example[\"ground_truth\"],\n",
        "        \"subject\": example[\"subject\"]\n",
        "    })\n",
        "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
        "model, tokenizer = FTHook.from_pretrained(model_name)\n",
        "\n",
        "edit_method = MEMITHook(model, tokenizer)\n",
        "\n",
        "trainer = EditTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    edit_method=edit_method,\n",
        "    config={\n",
        "        \"batch_size\": 1,\n",
        "        \"max_length\": 128,\n",
        "        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "        \"lr\": 5e-5,\n",
        "        \"edit_lr\": 5e-3,\n",
        "        \"num_epochs\": 1,\n",
        "        \"num_edits\": len(edit_examples),\n",
        "    }\n",
        ")\n",
        "\n",
        "metrics, edited_model, _ = trainer.train(edit_examples)\n",
        "\n",
        "print(metrics)\n",
        "\n",
        "test_prompt = \"What is the capital of France?\"\n",
        "input_ids = tokenizer.encode(test_prompt, return_tensors=\"pt\")\n",
        "output = edited_model.generate(input_ids, max_length=50)\n",
        "print(tokenizer.decode(output[0]))"
      ],
      "metadata": {
        "id": "SqOnMDgl28fe"
      },
      "id": "SqOnMDgl28fe",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "EasyEdit",
      "language": "python",
      "name": "easyedit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}